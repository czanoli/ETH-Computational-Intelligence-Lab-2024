{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticons = [\n",
    "    \":)\", \":-)\", \":(\", \":-(\", \":D\", \":-D\", \":P\", \":-P\", \";)\", \";-)\", \":O\", \":-O\", \":o\", \":-o\",\n",
    "    \":S\", \":-S\", \":'(\", \":'-(\", \":|\", \":-|\", \">:(\", \">:-(\", \":/\", \":-/\", \":\\\\\", \"://\", \":-\\\\\", \":*\", \":-*\",\n",
    "    \"<3\", \"</3\", \":-X\", \":X\", \":-#\", \":#\", \":-&\", \":&\", \":-$\", \":$\", \":-!\", \":!\", \":-@\", \":@\",\n",
    "    \":^)\", \":^(\", \"O:)\", \"O:-)\", \"3:)\", \"3:-)\", \">:)\", \">:-)\", \":-(\", \":-)\", \":-(\", \":-)\", \":-|\",\n",
    "    \":-D\", \":-P\", \":-O\", \":-*\", \":3\", \":>\", \":<\", \":]\", \":[\", \":}\", \":{\", \":^\", \"8-)\", \"B-)\", \"8)\",\n",
    "    \"B)\", \":-J\", \":(\", \":|\", \"xD\", \"XD\", \"xP\", \"XP\", \"DX\", \"X(\", \"XO\", \"XP\", \"8-)\", \"8-(\", \">:o\",\n",
    "    \">:-o\", \">:-O\", \">:-(\", \">:-)\", \":-b\", \":b\", \":-p\", \":p\", \":-d\", \":d\", \":-q\", \":q\", \":-/\",\n",
    "    \":/\", \":-|\", \":|\", \":-(\", \":-)\", \":-(\", \":-)\", \":-|\", \":-D\", \":-P\", \":-O\", \":-*\", \":3\", \":>\",\n",
    "    \":<\", \":]\", \":[\", \":}\", \":{\", \":^\", \"8-)\", \"B-)\", \"8)\", \"B)\", \":-J\", \":(\", \":|\", \"xD\", \"XD\",\n",
    "    \"xP\", \"XP\", \"DX\", \"X(\", \"XO\", \"XP\", \"8-)\", \"8-(\", \">:o\", \">:-o\", \">:-O\", \">:-(\", \">:-)\",\n",
    "    \":-b\", \":b\", \":-p\", \":p\", \":-d\", \":d\", \":-q\", \":q\", \":-/\", \":/\", \":-|\", \":|\", \":-(\", \":-)\",\n",
    "    \":-(\", \":-)\", \":-|\", \":-D\", \":-P\", \":-O\", \":-*\", \":3\", \":>\", \":<\", \":]\", \":[\", \":}\", \":{\",\n",
    "    \":^\", \"8-)\", \"B-)\", \"8)\", \"B)\", \":-J\", \":(\", \":|\", \"xD\", \"XD\", \"xP\", \"XP\", \"DX\", \"X(\", \"XO\",\n",
    "    \"XP\", \"8-)\", \"8-(\", \">:o\", \">:-o\", \">:-O\", \">:-(\", \">:-)\", \":-b\", \":b\", \":-p\", \":p\", \":-d\",\n",
    "    \":d\", \":-q\", \":q\", \":-/\", \":/\", \":-|\", \":|\", \":-(\", \":-)\", \":-(\", \":-)\", \":-|\", \":-D\", \":-P\",\n",
    "    \":-O\", \":-*\", \":3\", \":>\", \":<\", \":]\", \":[\", \":}\", \":{\", \":^\", \"8-)\", \"B-)\", \"8)\", \"B)\", \":-J\",\n",
    "    \":(\", \":|\", \"xD\", \"XD\", \"xP\", \"XP\", \"DX\", \"X(\", \"XO\", \"XP\", \"8-)\", \"8-(\", \">:o\", \">:-o\",\n",
    "    \">:-O\", \">:-(\", \">:-)\", \":-b\", \":b\", \":-p\", \":p\", \":-d\", \":d\", \":-q\", \":q\", \":-/\", \":/\",\n",
    "    \":-|\", \":|\", \":-(\", \":-)\", \":-(\", \":-)\", \":-|\", \":-D\", \":-P\", \":-O\", \":-*\", \":3\", \":>\", \":<\",\n",
    "    \":]\", \":[\", \":}\", \":{\", \":^\", \"8-)\", \"B-)\", \"8)\", \"B)\", \":-J\", \":(\", \":|\", \"xD\", \"XD\", \"xP\",\n",
    "    \"XP\", \"DX\", \"X(\", \"XO\", \"XP\", \"8-)\", \"8-(\", \">:o\", \">:-o\", \">:-O\", \">:-(\", \">:-)\", \":-b\",\n",
    "    \":b\", \":-p\", \":p\", \":-d\", \":d\", \":-q\", \":q\", \":-/\", \":/\", \":-|\", \":|\", \":-(\", \":-)\", \":-(\",\n",
    "    \":-)\", \":-|\", \":-D\", \":-P\", \":-O\", \":-*\", \":3\", \":>\", \":<\", \":]\", \":[\", \":}\", \":{\", \":^\",\n",
    "    \"8-)\", \"B-)\", \"8)\", \"B)\", \":-J\", \":(\", \":|\", \"xD\", \"XD\", \"xP\", \"XP\", \"DX\", \"X(\", \"XO\", \"XP\",\n",
    "    \"8-)\", \"8-(\", \">:o\", \">:-o\", \">:-O\", \">:-(\", \">:-)\", \":-b\", \":b\", \":-p\", \":p\", \":-d\", \":d\",\n",
    "    \":-q\", \":q\", \":-/\", \":/\", \":-|\", \":|\", \":-(\", \":-)\", \":-(\", \":-)\", \":-|\", \":-D\", \":-P\", \":-O\",\n",
    "    \":-*\", \":3\", \":>\", \":<\", \":]\", \":[\", \":}\", \":{\", \":^\", \"8-)\", \"B-)\", \"8)\", \"B)\", \":-J\", \":(\",\n",
    "    \":|\", \"xD\", \"XD\", \"xP\", \"XP\", \"DX\", \"X(\", \"XO\", \"XP\", \"8-)\", \"8-(\", \">:o\", \">:-o\", \">:-O\",\n",
    "    \">:-(\", \">:-)\", \":-b\", \":b\", \":-p\", \":p\", \":-d\", \":d\", \":-q\", \":q\", \":-/\", \":/\", \":-|\", \":|\",\n",
    "    \":-(\", \":-)\", \":-(\", \":-)\", \":-|\", \":-D\", \":-P\", \":-O\", \":-*\", \":3\", \":>\", \":<\", \":]\", \":[\",\n",
    "    \":}\", \":{\", \":^\", \"8-)\", \"B-)\", \"8)\", \"B)\", \":-J\", \":(\", \":|\", \"xD\", \"XD\", \"xP\", \"XP\", \"DX\",\n",
    "    \"X(\", \"XO\", \"XP\", \"8-)\", \"8-(\", \">:o\", \">:-o\", \">:-O\", \">:-(\", \">:-)\", \":-b\", \":b\", \":-p\",\n",
    "    \":p\", \":-d\", \":d\", \":-q\", \":q\", \":-/\", \":/\", \":-|\", \":|\", \":-(\", \":-)\", \":-(\", \":-)\", \":-|\",\n",
    "    \":-D\", \":-P\", \":-O\", \":-*\", \":3\", \":>\", \":<\", \":]\", \":[\", \":}\", \":{\", \":^\", \"8-)\", \"B-)\",\n",
    "    \"8)\", \"B)\", \":-J\", \":(\", \":|\", \"xD\", \"XD\", \"xP\", \"XP\", \"DX\", \"X(\", \"XO\", \"XP\", \"8-)\", \"8-(\",\n",
    "    \">:o\", \">:-o\", \">:-O\", \">:-(\", \">:-)\", \":-b\", \":b\", \":-p\", \":p\", \":-d\", \":d\", \":-q\", \":q\",\n",
    "    \":-/\", \":/\", \":-|\", \":|\", \":-(\", \":-)\", \":-(\", \":-)\", \":-|\", \":-D\", \":-P\", \":-O\", \":-*\",\n",
    "    \":3\", \":>\", \":<\", \":]\", \":[\", \":}\", \":{\", \":^\", \"8-)\", \"B-)\", \"8)\", \"B)\", \":-J\", \":(\", \":|\",\n",
    "    \"xD\", \"XD\", \"xP\", \"XP\", \"DX\", \"X(\", \"XO\", \"XP\", \"8-)\", \"8-(\", \">:o\", \">:-o\", \">:-O\", \">:-(\",\n",
    "    \">:-)\", \":-b\", \":b\", \":-p\", \":p\", \":-d\", \":d\", \":-q\", \":q\", \":-/\", \":/\", \":-|\", \":|\", \":-(\",\n",
    "    \":-)\", \":-(\", \":-)\", \":-|\", \":-D\", \":-P\", \":-O\", \":-*\", \":3\", \":>\", \":<\", \":]\", \":[\", \":}\",\n",
    "    \":{\", \":^\", \"8-)\", \"B-)\", \"8)\", \"B)\", \":-J\", \":(\", \":|\", \"xD\", \"XD\", \"xP\", \"XP\", \"DX\", \"X(\",\n",
    "    \"XO\", \"XP\", \"8-)\", \"8-(\", \">:o\", \">:-o\", \">:-O\", \":)\", \":-)\", \":(\", \":-(\", \":D\", \":-D\", \"xD\", \"XD\", \n",
    "    \":P\", \":-P\", \";)\", \";-)\", \":O\", \":-O\", \":o\", \":-o\", ':\\\\', '>:[', ':[ ', '-___-', 'o_o', '^ ^',\n",
    "    \":S\", \":-S\", \":'(\", \":'-(\", \":|\", \":-|\", \"D:\", \":/\", \":-/\", \":\\\\\", \":-\\\\\", \":*\", \":-*\", \"<3\", \"</3\",\n",
    "    \"\\\\o/\", \"\\\\m/\", \"^_^\", \"-_-\", \"o_O\", \">_<\", \":3\", \"(╯°□°）╯︵ ┻━┻\", \"┬─┬ ノ( ゜-゜ノ)\",\n",
    "    \"( ͡° ͜ʖ ͡°)\", \"(¬‿¬)\", \"(¬_¬)\", \"(ʘ‿ʘ)\", \"(ಥ﹏ಥ)\", \"(ಥ_ಥ)\", \"(づ｡◕‿‿◕｡)づ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_meanings = {\n",
    "    '-_-': 'annoyance',\n",
    "    '8)': 'cool',\n",
    "    '8-)': 'cool',\n",
    "    ':(': 'sad',\n",
    "    ':)': 'happy',\n",
    "    ':*': 'kiss',\n",
    "    ':-/': 'skeptical',\n",
    "    ':-@': 'scream',\n",
    "    ':-\\\\': 'annoyed',\n",
    "    ':-d': 'grin',\n",
    "    ':-p': 'playful',\n",
    "    ':-|': 'neutral',\n",
    "    ':/': 'skeptical',\n",
    "    ':3': 'cute',\n",
    "    ':<': 'sad',\n",
    "    ':>': 'smug',\n",
    "    ':@': 'angry',\n",
    "    ':[ ': 'sad',\n",
    "    ':-\\\\': 'annoyed',\n",
    "    ':]': 'happy',\n",
    "    ':d': 'grin',\n",
    "    ':o': 'surprised',\n",
    "    ':p': 'playful',\n",
    "    ':{': 'sad',\n",
    "    ':|': 'neutral',\n",
    "    ':}': 'happy',\n",
    "    ';)': 'wink',\n",
    "    '</3': 'heartbreak',\n",
    "    '<3': 'love',\n",
    "    '^_^': 'joy',\n",
    "    ':\\\\': 'skeptical',\n",
    "    '>:[': 'angry',\n",
    "    ':[': 'sad',\n",
    "    '-___-': 'annoyance',\n",
    "    'o_o': 'surprised',\n",
    "    '^ ^': 'joy'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from ydata_profiling import ProfileReport\n",
    "import re\n",
    "import contractions\n",
    "import emoji\n",
    "\n",
    "class DataProcessor:\n",
    "    def __init__(self):\n",
    "        self.nan_policy = \"drop\"\n",
    "        self.duplicates_policy = \"drop\"\n",
    "        self.shared_duplicates_policy = \"drop\"\n",
    "        self.conflict_policy = \"drop\"\n",
    "        self.dataset_type = \"full\"\n",
    "        self.train_files = [\"../../data/raw/train_pos_full.txt\", \"../../data/raw/train_neg_full.txt\"]\n",
    "    \n",
    "    def load_training_data(self):\n",
    "        if self.dataset_type not in [\"full\", \"small\"]:\n",
    "            raise ValueError(f\"Invalid training dataset_type. Expected one of full | small\")\n",
    "        df = pd.DataFrame()\n",
    "        for file in self.train_files:\n",
    "            label = \"positive\" if \"pos\" in file else \"negative\" if \"neg\" in file else None\n",
    "            with open(file, 'r', encoding='utf-8') as file:\n",
    "                tweets = file.readlines()\n",
    "            tmp_df = pd.DataFrame(tweets, columns=[\"tweet\"])\n",
    "            tmp_df[\"label\"] = label\n",
    "            df = pd.concat([df, tmp_df], ignore_index=True)\n",
    "        return df\n",
    "        \n",
    "    def nulls_info(self, df):\n",
    "        return df.isnull().sum()\n",
    "    \n",
    "    def profile(self, df):\n",
    "        profile = ProfileReport(df, title=\"Twitter Sentiment EDA Report\", minimal=True)\n",
    "        profile.to_file(self.prj_dir / f\"reports/twitter_sentiment_eda_{self.dataset_type}.html\")\n",
    "        \n",
    "    def process_dataframe(self, df, df2=None):\n",
    "        \"\"\"\n",
    "        Process the DataFrame based on the specified policies.\n",
    "        \n",
    "        Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        df2 (pd.DataFrame, optional): The second DataFrame for shared duplicates processing. Default is None.\n",
    "        \n",
    "        Returns:\n",
    "        tuple: The processed DataFrame(s). If df2 is None, returns (df,). Otherwise, returns (df, df2).\n",
    "        \"\"\"\n",
    "        # 1. Handle null values\n",
    "        if self.nan_policy == \"drop\":\n",
    "            df = df.dropna()\n",
    "        \n",
    "        # 2. Handle duplicates\n",
    "        if self.duplicates_policy == \"drop\":\n",
    "            df = df.drop_duplicates()\n",
    "        elif self.duplicates_policy == \"keep\":\n",
    "            df = df[df.duplicated(keep=False)]\n",
    "            \n",
    "        # 3. Handle conflicting tweets\n",
    "        conflict_tweets = df[df.duplicated(subset='tweet', keep=False)]\n",
    "        if self.conflict_policy == \"drop\":\n",
    "            df = df[~df['tweet'].isin(conflict_tweets['tweet'])]\n",
    "        elif self.conflict_policy == \"keep\":\n",
    "            df = conflict_tweets\n",
    "            \n",
    "        # 4. Lowercase\n",
    "        df['tweet'] = df['tweet'].apply(lambda x: x.lower())\n",
    "        \n",
    "        # 5. Remove <user> and <url>\n",
    "        df['tweet'] = df['tweet'].str.replace('<user>', '', regex=False)\n",
    "        df['tweet'] = df['tweet'].str.replace('<url>', '', regex=False)\n",
    "        \n",
    "        # 6. Whitespace Stripping\n",
    "        df['tweet'] = df['tweet'].apply(lambda x: x.strip())\n",
    "        df['tweet'] = df['tweet'].apply(lambda x: \" \".join(x.split()))\n",
    "        \n",
    "        # 7. Expand contractions\n",
    "        df['tweet'] = df['tweet'].apply(contractions.fix)\n",
    "\n",
    "        # 8.1 De-emojize [Creativity]\n",
    "        df['tweet'] = df['tweet'].apply(lambda x: emoji.demojize(x, delimiters=(\" \", \" \")))\n",
    "        df['tweet'] = df['tweet'].replace(\":\", \"\").replace(\"_\", \" \")\n",
    "        \n",
    "        # 8.2 De-emoticonize [Creativity]\n",
    "        pattern = re.compile('|'.join(map(re.escape, emoticon_meanings.keys())))\n",
    "        df['tweet'] = df['tweet'].apply(lambda tweet: pattern.sub(lambda x: emoticon_meanings[x.group()], tweet))\n",
    "        \n",
    "        '''\n",
    "        [//TODO IN ORDER]\n",
    "        > Handling Slang. Note: augment vocabulary by inspecting data\n",
    "        \n",
    "        > Stop-word removal\n",
    "        \n",
    "        > Handling Numerical values (remove)\n",
    "        \n",
    "        > Handle hashtag [creativity]: remove symbol and, for each hashtag, split it into the comprising words. \n",
    "        Then new columns? Append to tweet? For sure they are useful for sercasm detection\n",
    "        Attenzione perchè qua, per ogni twwt, ogni hashtag devi separarlo nelle sue parole componenti. Vedi wordsegment\n",
    "        #df['hashtags'] = df['tweet'].apply(lambda x: re.findall(r\"#(\\S+)\", x))\n",
    "        #df['tweet'] = df['tweet'].apply(lambda x: re.sub(r\"#\\S+\", \"\", x))\n",
    "\n",
    "        > Spelling correction (multiple letters, switched letters)\n",
    "        \n",
    "        > Remove Punctuation\n",
    "        \n",
    "        > Non-words / short/rare words removal\n",
    "        \n",
    "        > Part-of-Speech tagging\n",
    "        \n",
    "        > Lemmatization\n",
    "        \n",
    "        > Sarcasm detection [creativity] => change sentiment polarity (heuristic or DL?)\n",
    "        \n",
    "        > Dimensionality Reduction [creativity]\n",
    "        \n",
    "        > Text encoding/ Vectorization\n",
    "        \n",
    "        > Label Encoding\n",
    "        '''\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processor = DataProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_processor.load_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data_processor.process_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
